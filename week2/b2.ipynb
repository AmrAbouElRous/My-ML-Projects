{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression with multiple Features\n",
    "Problem Statement: Calculate housing price <br><br>\n",
    "<img src =./Images/b12.png><img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature   Feature   Feature   Feature   Feature\n",
      "[[2104    5    1   45]\n",
      " [1416    3    2   40]\n",
      " [ 852    2    1   35]]\n",
      " shape (3, 4) (row,column) \n",
      " type <class 'numpy.ndarray'>\n",
      "3\n",
      "4\n",
      "(3, 4)\n"
     ]
    }
   ],
   "source": [
    "import math,copy\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "np.set_printoptions(precision=2) # 2 digits after the decimal point to make numbers more readable\n",
    "\n",
    "X_train = np.array([[2104, 5, 1, 45], [1416, 3, 2, 40], [852, 2, 1, 35]])\n",
    "print(\"Feature   Feature   Feature   Feature   Feature\")\n",
    "print(f\"{X_train}\\n shape {X_train.shape} (row,column) \\n type {type(X_train)}\")\n",
    "y_train=np.array([460,232,178])\n",
    "\n",
    "print(X_train.shape[0])\n",
    "print(X_train.shape[-1])\n",
    "print(X_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =./Images/b13.png></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One Weight per feature not per Iteration<br><br>\n",
    "<img src =./Images/b14.png></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_init = 785.1811367994083\n",
    "w_init = np.array([ 0.39133535, 18.75376741, -53.36032453, -26.42131618]) #one weight for each feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = ./Images/b15.png></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute_cost\n",
    "def compute_cost(X,y,w,b):\n",
    "    \"\"\"\n",
    "    X array \n",
    "    w vector\n",
    "    b scalar\n",
    "    \"\"\"\n",
    "    m=X.shape[0]\n",
    "    cost=0\n",
    "    for i in range(m):\n",
    "        cost = cost + ( (np.dot(X[i],w)+b) - y[i] )**2\n",
    "\n",
    "    cost=cost/(2*m)\n",
    "\n",
    "    return cost\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5578904428966628e-12\n"
     ]
    }
   ],
   "source": [
    "cost = compute_cost(X_train,y_train,w_init,b_init)\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = ./Images/b16.png/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "m=np.zeros(4)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradiant(X,y,w,b):\n",
    "    \"\"\" \n",
    "        X array\n",
    "        y scalar\n",
    "        w vector \n",
    "        b scalr\n",
    "        dj/dw = 1/m  sum of ((w*x+b)-y)*x sup(i) sub(j)     \n",
    "        dj/db = 1/m  sum of ((w*x+b)-y)         \n",
    "\n",
    "    \"\"\"\n",
    "    m,n = X.shape # rows and columns (iterations,features)\n",
    "    d_dw = np.zeros(n)\n",
    "    d_db=0\n",
    "    for i in range(m):\n",
    "        err = (np.dot(w,X[i])+b) -y[i]\n",
    "        d_dw = d_dw + np.dot(err,X[i])\n",
    "        \n",
    "        d_db = d_db + err\n",
    "    d_dw = d_dw / m                                \n",
    "    d_db = d_db / m\n",
    "\n",
    "    return d_dw,d_db\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.73e-03 -6.27e-06 -2.22e-06 -6.92e-05] \n",
      "  -1.6739251501955248e-06\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tmp_d_dw,tmp_d_db = compute_gradiant(X_train,y_train,w_init,b_init)\n",
    "print(f\"{tmp_d_dw} \\n  {tmp_d_db}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradiant Descent with multiple variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X,y,w_in,b_in,cost_function,gradiant_function,learning_rate,num_iteration):\n",
    "    \"\"\"\n",
    "    Repeat until convergence (repeat with many many iterations)\n",
    "    w = w - learning rate * d/dw\n",
    "    b = b - learning rate * d/db\n",
    "    \"\"\"\n",
    "   \n",
    "    J_history=[] # history of the cost\n",
    "    w= copy.deepcopy(w_in)\n",
    "    b =copy.deepcopy(b_in)\n",
    "    for i in range(num_iteration):\n",
    "        d_dw,d_db=gradiant_function(X,y,w,b)\n",
    "        w = w - (learning_rate * d_dw)\n",
    "        b = b - (learning_rate *d_db)\n",
    "        if i < 100000:\n",
    "            J_history.append(cost_function(X,y,w,b)) #store the history of the cost function\n",
    "\n",
    "        if i% math.ceil(num_iteration/10)==0:\n",
    "            print(f\"Iteration {i:4d} : cost {J_history[-1]:8.2f}\")\n",
    "    \n",
    "    return w,b,J_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration    0 : cost  2529.46\n",
      "Iteration  100 : cost   695.99\n",
      "Iteration  200 : cost   694.92\n",
      "Iteration  300 : cost   693.86\n",
      "Iteration  400 : cost   692.81\n",
      "Iteration  500 : cost   691.77\n",
      "Iteration  600 : cost   690.73\n",
      "Iteration  700 : cost   689.71\n",
      "Iteration  800 : cost   688.70\n",
      "Iteration  900 : cost   687.69\n",
      "b,w found by gradient descent: -0.00,[ 0.2   0.   -0.01 -0.07] \n",
      "prediction: 426.19, target value: 460\n",
      "prediction: 286.17, target value: 232\n",
      "prediction: 171.47, target value: 178\n"
     ]
    }
   ],
   "source": [
    "# initialize parameters\n",
    "m,n = X_train.shape\n",
    "initial_w = np.zeros(n)\n",
    "initial_b = 0.\n",
    "# some gradient descent settings\n",
    "iterations = 1000\n",
    "alpha = 5.0e-7\n",
    "# run gradient descent \n",
    "w_final, b_final, J_hist = gradient_descent(X_train, y_train, initial_w, initial_b,compute_cost,compute_gradiant,alpha,iterations) \n",
    "            \n",
    "print(f\"b,w found by gradient descent: {b_final:0.2f},{w_final} \")\n",
    "\n",
    "for i in range(m):\n",
    "    print(f\"prediction: {np.dot(X_train[i], w_final) + b_final:0.2f}, target value: {y_train[i]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
